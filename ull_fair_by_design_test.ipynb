{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from fairness.matching import conscious_fairness_through_unawareness\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./dataset/ull/ULL_dataset.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>scores</th>\n",
       "      <th>score_mat</th>\n",
       "      <th>level_mat</th>\n",
       "      <th>score_len</th>\n",
       "      <th>level_len</th>\n",
       "      <th>score_ing</th>\n",
       "      <th>level_ing</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>...</th>\n",
       "      <th>p331a</th>\n",
       "      <th>p331b</th>\n",
       "      <th>p331c</th>\n",
       "      <th>p331d</th>\n",
       "      <th>p331e</th>\n",
       "      <th>p331f</th>\n",
       "      <th>p331g</th>\n",
       "      <th>p331j</th>\n",
       "      <th>pfc</th>\n",
       "      <th>rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>564.8700</td>\n",
       "      <td>3.0</td>\n",
       "      <td>535.1500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>500.461528</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>388.3400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>293.7000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500.461528</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>386.5900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>514.8100</td>\n",
       "      <td>3.0</td>\n",
       "      <td>500.461528</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>487.7600</td>\n",
       "      <td>2.0</td>\n",
       "      <td>449.2500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>500.461528</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>709.7900</td>\n",
       "      <td>4.0</td>\n",
       "      <td>598.7200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>500.461528</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83852</th>\n",
       "      <td>83852</td>\n",
       "      <td>1</td>\n",
       "      <td>400.8625</td>\n",
       "      <td>2.0</td>\n",
       "      <td>446.6522</td>\n",
       "      <td>2.0</td>\n",
       "      <td>294.747400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83853</th>\n",
       "      <td>83853</td>\n",
       "      <td>1</td>\n",
       "      <td>597.0243</td>\n",
       "      <td>3.0</td>\n",
       "      <td>632.6043</td>\n",
       "      <td>4.0</td>\n",
       "      <td>633.296600</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83854</th>\n",
       "      <td>83854</td>\n",
       "      <td>1</td>\n",
       "      <td>707.9254</td>\n",
       "      <td>4.0</td>\n",
       "      <td>400.2761</td>\n",
       "      <td>2.0</td>\n",
       "      <td>477.505600</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83855</th>\n",
       "      <td>83855</td>\n",
       "      <td>1</td>\n",
       "      <td>522.8511</td>\n",
       "      <td>3.0</td>\n",
       "      <td>656.1601</td>\n",
       "      <td>4.0</td>\n",
       "      <td>540.112200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83856</th>\n",
       "      <td>83856</td>\n",
       "      <td>1</td>\n",
       "      <td>519.1200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>426.1871</td>\n",
       "      <td>2.0</td>\n",
       "      <td>453.685400</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83857 rows Ã— 549 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  scores  score_mat  level_mat  score_len  level_len  \\\n",
       "0               0       1   564.8700        3.0   535.1500        3.0   \n",
       "1               1       1   388.3400        1.0   293.7000        1.0   \n",
       "2               2       1   386.5900        1.0   514.8100        3.0   \n",
       "3               3       1   487.7600        2.0   449.2500        2.0   \n",
       "4               4       1   709.7900        4.0   598.7200        3.0   \n",
       "...           ...     ...        ...        ...        ...        ...   \n",
       "83852       83852       1   400.8625        2.0   446.6522        2.0   \n",
       "83853       83853       1   597.0243        3.0   632.6043        4.0   \n",
       "83854       83854       1   707.9254        4.0   400.2761        2.0   \n",
       "83855       83855       1   522.8511        3.0   656.1601        4.0   \n",
       "83856       83856       1   519.1200        3.0   426.1871        2.0   \n",
       "\n",
       "        score_ing  level_ing   a1      a2  ...  p331a  p331b  p331c  p331d  \\\n",
       "0      500.461528        2.0  2.0  2007.0  ...    4.0    4.0    4.0    4.0   \n",
       "1      500.461528        2.0  1.0  2007.0  ...    4.0    4.0    4.0    4.0   \n",
       "2      500.461528        2.0  2.0  2007.0  ...    4.0    4.0    4.0    4.0   \n",
       "3      500.461528        2.0  1.0  2007.0  ...    2.0    2.0    3.0    2.0   \n",
       "4      500.461528        2.0  2.0  2007.0  ...    4.0    4.0    4.0    4.0   \n",
       "...           ...        ...  ...     ...  ...    ...    ...    ...    ...   \n",
       "83852  294.747400        1.0  2.0  2007.0  ...    4.0    4.0    4.0    4.0   \n",
       "83853  633.296600        4.0  2.0  2007.0  ...    3.0    4.0    4.0    4.0   \n",
       "83854  477.505600        2.0  1.0  2007.0  ...    4.0    4.0    4.0    4.0   \n",
       "83855  540.112200        3.0  2.0  2007.0  ...    3.0    3.0    3.0    3.0   \n",
       "83856  453.685400        2.0  1.0  2007.0  ...    4.0    4.0    4.0    4.0   \n",
       "\n",
       "       p331e  p331f  p331g  p331j   pfc  rep  \n",
       "0        4.0    3.0    5.0    4.0   3.0  2.0  \n",
       "1        4.0    3.0    5.0    4.0   3.0  2.0  \n",
       "2        4.0    3.0    5.0    4.0   3.0  2.0  \n",
       "3        3.0    3.0    5.0    4.0   3.0  2.0  \n",
       "4        4.0    3.0    5.0    4.0   3.0  2.0  \n",
       "...      ...    ...    ...    ...   ...  ...  \n",
       "83852    4.0    3.0    5.0    3.0  10.0  2.0  \n",
       "83853    4.0    3.0    5.0    4.0   3.0  2.0  \n",
       "83854    4.0    3.0    5.0    4.0   3.0  2.0  \n",
       "83855    3.0    3.0    3.0    3.0   8.0  1.0  \n",
       "83856    4.0    4.0    4.0    4.0   3.0  2.0  \n",
       "\n",
       "[83857 rows x 549 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of the dataset:  549\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns of the dataset: \", len(dataset.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_columns = ['level_mat', 'level_len', 'level_ing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_attributes = ['score_MAT', 'level_MAT', 'score_LEN', 'level_LEN', 'score_ING',\n",
    "       'level_ING', 'a1', 'a4', 'repeater', 'a24', 'a41', 'a42',\n",
    "       'country_iso_cnac', 'country_iso_nac', 'island', 'capital_island',\n",
    "       'public_private', 'f3a', 'f3b', 'mother_education',\n",
    "       'father_education', 'f4a', 'f4b', 'f5a', 'f5b', 'f5n', 'inmigrant',\n",
    "       'inmigrant2', 'inmigrant_second_gen', 'f11', 'books', 'f23',\n",
    "       'f24a', 'f24b', 'mother_occupation', 'father_occupation', 'f34',\n",
    "       'household_income_q', 'escs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_attributes = [x.lower() for x in protected_attributes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "random_forest_classifier = RandomForestClassifier()\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "models = [\n",
    "    random_forest_classifier,\n",
    "    decision_tree_classifier\n",
    "]\n",
    "\n",
    "random_forest_params = {\n",
    "    'min_samples_leaf': [5, 7, 9, 11],\n",
    "    'n_estimators': [200, 500],\n",
    "    'max_depth' : [10, 20, 50, 80, 100, 150],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "decision_tree_params = {\n",
    "    'min_samples_leaf': [5, 7, 9, 11],\n",
    "    'max_depth' : [10, 20, 50, 80, 100, 150],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "\n",
    "model_params = [random_forest_params, decision_tree_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=['Unnamed: 0', 'scores'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     protected_attributes \u001b[39m=\u001b[39m protected_attributes\n\u001b[1;32m----> 8\u001b[0m fair_dataset \u001b[39m=\u001b[39m conscious_fairness_through_unawareness(dataset, protected_attributes, output_column_values, output_column)\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mColumns of the fair dataset: \u001b[39m\u001b[39m\"\u001b[39m, fair_dataset\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m     11\u001b[0m X \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mloc[:, dataset\u001b[39m.\u001b[39mcolumns\u001b[39m!=\u001b[39moutput_column]\n",
      "File \u001b[1;32mc:\\Users\\anton\\Desktop\\experiments-fair-by-design-via-apriori\\fairness\\matching\\__init__.py:16\u001b[0m, in \u001b[0;36mconscious_fairness_through_unawareness\u001b[1;34m(dataset, protected_attributes, output_column_values, output_column, columns_to_drop, confidence_threshold)\u001b[0m\n\u001b[0;32m     14\u001b[0m final_dataset \u001b[39m=\u001b[39m remove_columns_from_dataset(numerical_dataset, columns_to_drop)\n\u001b[0;32m     15\u001b[0m fixed_dataset \u001b[39m=\u001b[39m fix_protected_attributes(final_dataset, protected_attributes)\n\u001b[1;32m---> 16\u001b[0m fairness_evaluation \u001b[39m=\u001b[39m DisparateImpact()\u001b[39m.\u001b[39;49mfairness_evaluation(fixed_dataset, protected_attributes, output_column_values, output_column)\n\u001b[0;32m     17\u001b[0m \u001b[39mprint\u001b[39m(fairness_evaluation)\n\u001b[0;32m     18\u001b[0m \u001b[39mwhile\u001b[39;00m fairness_evaluation \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39munfair\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\anton\\Desktop\\experiments-fair-by-design-via-apriori\\fairness\\fairness_metric\\disparate_impact.py:33\u001b[0m, in \u001b[0;36mDisparateImpact.fairness_evaluation\u001b[1;34m(self, dataset, protected_attributes, output_column_values, output_column)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfairness_evaluation\u001b[39m(\u001b[39mself\u001b[39m, dataset: pd\u001b[39m.\u001b[39mDataFrame, protected_attributes: \u001b[39mlist\u001b[39m, output_column_values: \u001b[39mlist\u001b[39m,\n\u001b[0;32m     25\u001b[0m                         output_column: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m     26\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39m    This method perform an evaluation of the fairness of a given dataset according to the Disparate Impact metric\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39m    :param dataset: this is the dataset on which to be labelled as fair or unfair\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39m    :return: return 'fair' if the dataset is fair, unfair 'otherwise'\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     bias_analysis_dataframe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_detection(dataset, protected_attributes, output_column_values, output_column)\n\u001b[0;32m     34\u001b[0m     return_value \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39munfair\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     35\u001b[0m     \u001b[39mfor\u001b[39;00m value \u001b[39min\u001b[39;00m bias_analysis_dataframe[\u001b[39m'\u001b[39m\u001b[39mDisparate Impact\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues:\n",
      "File \u001b[1;32mc:\\Users\\anton\\Desktop\\experiments-fair-by-design-via-apriori\\fairness\\fairness_metric\\disparate_impact.py:21\u001b[0m, in \u001b[0;36mDisparateImpact.bias_detection\u001b[1;34m(self, dataset, protected_attributes, output_column_values, output_column)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbias_detection\u001b[39m(\u001b[39mself\u001b[39m, dataset: pd\u001b[39m.\u001b[39mDataFrame, protected_attributes: \u001b[39mlist\u001b[39m, output_column_values: \u001b[39mlist\u001b[39m, output_column: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[0;32m      8\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m    This method check the disparate impact for each sensitive attributes in the dataset and returns a dataframe in\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39m    which a column is the series of attributes and a column is the disparate impact value for each attribute\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreturn_disparate_impact(dataset, protected_attributes, output_column_values, output_column)\n",
      "File \u001b[1;32mc:\\Users\\anton\\Desktop\\experiments-fair-by-design-via-apriori\\fairness\\fairness_metric\\disparate_impact.py:59\u001b[0m, in \u001b[0;36mDisparateImpact.return_disparate_impact\u001b[1;34m(self, dataset, protected_attributes, output_column_values, output_column)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mfor\u001b[39;00m output_value \u001b[39min\u001b[39;00m output_column_values:\n\u001b[0;32m     58\u001b[0m     \u001b[39mfor\u001b[39;00m attribute \u001b[39min\u001b[39;00m protected_attributes:\n\u001b[1;32m---> 59\u001b[0m         unprivileged_probability \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_disparate_impact(dataset, attribute, \u001b[39m0\u001b[39;49m,\n\u001b[0;32m     60\u001b[0m                                                              output_column, output_value)\n\u001b[0;32m     62\u001b[0m         privileged_probability \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_disparate_impact(dataset, attribute, \u001b[39m1\u001b[39m,\n\u001b[0;32m     63\u001b[0m                                                            output_column, output_value)\n\u001b[0;32m     65\u001b[0m         \u001b[39mif\u001b[39;00m privileged_probability \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\anton\\Desktop\\experiments-fair-by-design-via-apriori\\fairness\\fairness_metric\\disparate_impact.py:88\u001b[0m, in \u001b[0;36mDisparateImpact.compute_disparate_impact\u001b[1;34m(self, dataset, protected_attribute, protected_attribute_value, output_column, output_value)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_disparate_impact\u001b[39m(\u001b[39mself\u001b[39m, dataset: pd\u001b[39m.\u001b[39mDataFrame, protected_attribute, protected_attribute_value,\n\u001b[0;32m     78\u001b[0m                              output_column, output_value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m     79\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[39m    This method computes the disparate impact value starting from the parameters\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39m    :param dataset: the dataset needed to perform the computation\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39m    :return:\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     attribute_columns_data \u001b[39m=\u001b[39m dataset[dataset[protected_attribute] \u001b[39m==\u001b[39;49m protected_attribute_value]\n\u001b[0;32m     89\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(attribute_columns_data[attribute_columns_data[output_column] \u001b[39m==\u001b[39m output_value]) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(\n\u001b[0;32m     90\u001b[0m         attribute_columns_data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:3798\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3796\u001b[0m \u001b[39m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   3797\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 3798\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_bool_array(key)\n\u001b[0;32m   3800\u001b[0m \u001b[39m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m \u001b[39m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m is_single_key \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:3852\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3849\u001b[0m \u001b[39m# check_bool_indexer will throw exception if Series key cannot\u001b[39;00m\n\u001b[0;32m   3850\u001b[0m \u001b[39m# be reindexed to match DataFrame rows\u001b[39;00m\n\u001b[0;32m   3851\u001b[0m key \u001b[39m=\u001b[39m check_bool_indexer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, key)\n\u001b[1;32m-> 3852\u001b[0m indexer \u001b[39m=\u001b[39m key\u001b[39m.\u001b[39;49mnonzero()[\u001b[39m0\u001b[39m]\n\u001b[0;32m   3853\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_take_with_is_copy(indexer, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for output_column in output_columns:\n",
    "    output_column_values = [int(x) for x in dataset[output_column]]\n",
    "    if output_column in protected_attributes:\n",
    "        protected_attributes.remove(output_column)\n",
    "    else:\n",
    "        protected_attributes = protected_attributes\n",
    "        \n",
    "    fair_dataset = conscious_fairness_through_unawareness(dataset, protected_attributes, output_column_values, output_column)\n",
    "    print(\"Columns of the fair dataset: \", fair_dataset.columns)\n",
    "    \n",
    "    X = dataset.loc[:, dataset.columns!=output_column]\n",
    "    y = output_column\n",
    "    y = np.ravel(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    standard_scaler_train = StandardScaler()\n",
    "    X_train = standard_scaler_train.fit_transform(X_train)\n",
    "\n",
    "    standard_scaler_test = StandardScaler()\n",
    "    X_test = standard_scaler_test.fit_transform(X_test)\n",
    "\n",
    "    best_params = None\n",
    "    max_accuracy = 0\n",
    "    best_model = None\n",
    "\n",
    "    for model_index in range(0, len(models)):\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "        estimator=models[model_index],\n",
    "        param_grid=model_params[model_index],\n",
    "        scoring='accuracy', \n",
    "        return_train_score=True,\n",
    "        cv=3\n",
    "        )\n",
    "\n",
    "        grid_search_classifier = grid_search.fit(X_train, y_train)\n",
    "        y_pred = grid_search_classifier.predict(X_test)\n",
    "\n",
    "        print(\"Output column: \", output_column)\n",
    "        print(\"Model: \", models[model_index])\n",
    "        print(\"Best params: \", grid_search_classifier.best_params_)\n",
    "        print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "        if accuracy_score(y_test, y_pred) > max_accuracy:\n",
    "            max_accuracy = accuracy_score(y_test, y_pred)\n",
    "            best_model = models[model_index]\n",
    "            best_params = grid_search_classifier.best_params_\n",
    "\n",
    "    print(\"OUTPUT COLUMN: \", output_column)\n",
    "    print(\"Best model: \", best_model)\n",
    "    print(\"Best_params: \", best_params)\n",
    "    print(\"Accuracy: \", max_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
